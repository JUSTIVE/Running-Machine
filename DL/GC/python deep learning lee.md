#h1 MASHIN LERANING

기계 학습 기술은 실제로 다양한 분야에 적용되고 있으며 데이터 과학자는 여러 산업 분야에서 연구되고 있습니다.

기계 학습을 통해 의사 결정을 내릴 수 있도록 데이터에서 쉽게 알 수 없는 지식을 얻는 프로세스를 식별합니다.

기계 학습 기술의 응용은 크게 다를 수 있으며 의학, 금융 및 광고와 같은 다양한 분야에 적용 할 수 있습니다.

이 장에서는 다양한 기계 학습 접근법과 기술 및 실제 문제에 대한 응용 프로그램을 소개하고 기계 학습,  Python에서 사용할 수있는 주요 오픈 소스 패키지 중 하나를 소개합니다.scikit-learn

이것은 우리가 뇌의 기능성, 특히 DEEP learning을 목표로 하는 신경 네트워크를 사용하는 특정한 유형의 기계 학습 접근법에 초점을 맞추는 차후의 장의 배경지식을 제공 할 것이다.

deep learing은 80 년대에 사용 된 것보다 더 진보 된 신경 네트워크를 사용합니다. 이론의 최근 발전뿐만 아니라 컴퓨터 속도의 향상과 GPU (Graphical Processing Units)의 사용 대 CPU의 전통적인 사용 ( 컴퓨팅 처리 장치)에도 기인함.

이 장은 주로 기계 학습이 할 수있는 것과 수행 할 수있는 것의 요약을 의미하며 독자가 알려진 전통적인 머신러닝과 차별화 된 학습 방법을 더 잘 이해할 수 있도록 독자를 준비시키기위한 것입니다.

--
특히, 이 챕터에서는 다음과 같은 내용을 다룹니다. 

• 기계 학습이란 무엇입니까? 
• 다양한 기계 학습 접근 방식 
• 기계 학습 시스템에 관련된 단계 
• 인기 있는 기술/알고리즘에 대한 간략한 설명 
• 실제 삶에 적용.
• 알려진 오픈 소스 패키지

#h2 왜 머신러닝을 배우지?

기계 학습은 종종 "빅 데이터"와 "인공지능" 또는 짧게는 A.I.와 같은 용어와 함께 언급되지만, 둘 다와는 상당히 다릅니다. 

기계 학습이 무엇이고 왜 유용한지 이해하기 위해서는 빅 데이터가 무엇이고 어떻게 기계 학습이 여기에 적용되는지를 이해하는 것이 중요합니다.

빅 데이터는 수집 및 저장되는 데이터의 큰 증가로 인해 생성되는 대규모 데이터 세트를 설명하는 데 사용되는 용어입니다.

구글은 혼자 하루에 20페타바이트 이상의 정보를 처리하는 것으로 추정되고 있으며 이 숫자는 증가할 것이다. 

IBM은 매일 250조 바이트가 생성되고 전세계 데이터의 90%가 지난 2년 동안 생성되었다고 추정했습니다. 

분명히 인간만으로는 엄청난 양의 데이터를 분석 할 수는 없지만 기계 학습 기술은 이러한 매우 큰 데이터 세트를 이해하는 데 사용됩니다

많은 머신러닝과 특히 딥러닝의 장점중 하나는 분석 및 예측 능력을 향상시키는 대규모 데이터 세트에 사용할 수 있을 때 가장 잘 작동한다는 것입니다. 

다른 말로는, 머신러닝, 특히 딥러닝 신경 네트워크는 데이터에 숨겨진 패턴과 정규성을 발견하기 위해 대용량 데이터 세트에 액세스할 수 있을 때 "학습"을 가장 잘 합니다.

---

반면에 기계 학습의 예측 능력은 인공 지능 시스템에 잘 적용될 수 있습니다.

기계 학습은 인공지능 시스템의 "두뇌"라고 생각할 수 있다. 인공 지능은 (이 정의가 독특하지는 않더라도) 환경과 상호작용할 수 있는 시스템으로 정의할 수 있다. 

인공 지능 기계에는 센서가 장착되어있어 자신이 속한 환경과 관련 지을 수있는 도구에 대해 알 수 있다.

따라서 기계 학습은 기계가 센서를 통해 섭취한 데이터를 분석하여 적절한 답을 만들 수 있도록 하는 두뇌입니다.

간단한 예는 아이폰의 시리이다. 시리는 마이크를 통해 명령을 듣고 스피커나 디스플레이를 통해 답을 출력하지만, 그렇게 하기 위해서는 올바른 대답을 만들기 위해 무엇을 "인식"해야 합니다. 

마찬가지로, 운전자 없는 자동차에는 카메라, GPS 시스템, 수중 음파탐지기 레이더가 장착될 것이지만, 이 모든 정보는 정확한 답을 제공하기 위해 처리되어야 한다. 즉, 가속, 제동, 회전 등. 답을 이끌어내는 정보처리는 기계학습의 의미를 나타낸다.

#h2 다양한 기계 학습 접근 방식

기계 학습이라는 용어는 우리가 본 것처럼 매우 일반적인 방법으로 사용되며, 그것은 큰 집합에서 패턴을 추론하거나 사용 가능한 데이터를 분석하여 학습된 것을 바탕으로 새로운 데이터에 대한 예측을 하는 일반적인 기술을 가리킨다. 

이것은 매우 일반적이며 광범위한 정의이며 다양한 기술을 포함합니다. 기계 학습 기술은 크게 두 가지 큰 클래스로 나눌 수 있습니다. 감독 및 감독되지 않은 학습(Supervised ad unsupervised learning)입니다. 하나 이상의 클래스가 종종 추가되며 강화 학습(Reinforcement learning)이라고합니다.

#h2 지도 학습.

기계 알고리즘의 첫 번째 클래스는 지도 학습으로 지정됩니다. 

감독(지도) 학습 알고리즘은 라벨링되지 않은 유사한 데이터를 분류하기 위해 라벨로 표시된 데이터 세트를 사용하는 기계 학습 알고리즘의 한 클래스입니다.

라벨화된 데이터는 이미 분류된 데이터이며 라벨화되지 않은 데이터는 아직 라벨링되지 않은 데이터입니다. 우리가 보게 될 것처럼 라벨은 불연속적이거나 연속적일 수 있다. 이 개념을 더 잘 이해하기 위해서, 예를 들어보자

사용자가 매일 많은 양의 전자 메일을 수신한다고 가정합니다. 그 중 일부는 중요한 비즈니스 전자 메일이고 일부는 요청되지 않은 정크 전자 메일 또는 스팸입니다.

감독되는 기계 알고리즘에는 사용자가 이미 스팸 또는 스팸이 아닌 스팸이라는 레이블을 지정한 대규모 전자 메일이 표시됩니다.

알고리즘은 모든 분류 된 데이터에 대해 실행되며 전자 메일이 스팸인지 아닌지에 대한 예측을합니다.

즉, 알고리즘이 각 예를 검사하고 전자 메일이 스팸인지 여부에 대해 각 예제에 대해 예측합니다. 

일반적으로 알고리즘이 레이블이 지정되지 않은 모든 데이터를 처음 실행할 때 많은 전자 메일에 레이블을 잘못 지정하며 성능이 상당히 저하될 수 있습니다. 그러나 각 실행 후 알고리즘은 예측값을 원하는 결과(레이블)와 비교합니다. 이를 통해 알고리즘은 성능과 정확성을 향상시키는 방법을 배우게 됩니다. 

위에서 언급했듯이, 이러한 종류의 접근 방식은 각 전자 메일이 스팸으로 분류 될 수있는 특성 (또는 기능)을 더 잘 학습 할 수있는 많은 양의 데이터로부터 이점을 얻을 수 있습니다.

알고리즘이 라벨 데이터 (흔히 훈련 데이터라고도 함)에서 잠시 동안 실행되고 정확도가 향상되지 않으면 새로운 전자 메일에서 새 레이블이 지정되지 않은 데이터의 정확성을 테스트 할 수 있습니다

그러나 이 `프로세스를 두 개 이상의 클래스로 일반화할 수 있다는 점을 유념`해야 합니다. 예를 들어, 소프트웨어를 실행하고 라벨이 개인, 비즈니스/워크, 사회, 혹은 스팸 레이블이 있는 전자 메일 세트에서 교육할 수 있습니다.

실제로 Google의 무료 전자 메일 서비스 인 Gmail은 사용자가 다음과 같은 다섯 가지 범주를 선택할 수 있도록합니다.

• 주, 개인 대 대화를 포함합니다.
• 소셜, 소셜 네트워크 및 미디어 공유 사이트의 메시지 포함
• 프로모션,마케팅 전자 메일, 쿠폰 및 할인을 포함.
• 업데이트, 은행 계좌 명세서 및 영수증을 포함한 청구서
• 포럼,온라인 그룹 및 메일 링리스트의 메시지가 포함

경우에 따라 결과가 반드시 개별적 일 필요는 없으며 데이터를 분류 할 수있는 클래스 수가 제한되어 있지 않을 수도 있습니다.

예를 들어, 우리는 사전 결정된 건강 매개 변수를 기반으로 한 집단의 평균 수명을 예측하려고 시도했을 수 있습니다. 이 경우 결과는 연속 함수이기 때문에 (우리는 기대 수명을 사람이 살 것으로 예상되는 실제 숫자로 지정할 수 있습니다) 우리는 분류 작업에 대해 이야기하지 않고 회귀 문제에 대해서만 이야기합니다.

감독 학습을 생각하는 한 가지 방법은 데이터 집합에 정의 된 함수 f를 작성하려고한다는 것입니다.

우리의 데이터 세트는 기능별로 구성된 정보로 구성됩니다. 전자 메일 분류의 예에서 이러한 기능은 스팸 전자 메일에서 다른 기능보다 자주 나타날 수있는 특정 단어 일 수 있습니다.

노골적인 성 관련 단어를 사용하면 비즈니스 / 업무용 전자 메일이 아닌 스팸 전자 메일을 식별 할 가능성이 높습니다. 반대로 "회의", "비즈니스"및 "프레젠테이션"과 같은 단어는 작업 전자 메일을보다 쉽게 설명합니다. 메타 데이터에 대한 액세스 권한이 있으면 보낸 사람 정보를 사용하여 전자 메일을 더 잘 분류 할 수도 있습니다.

각 전자 메일에는 일련의 기능이 관련되며 각 기능에는 값이 있습니다(이 경우 전자 메일 본문에 특정 단어가 있는 횟수). 

그런 다음 기계 학습 알고리즘은 이러한 값을 클래스 집합을 나타내는 이산형 범위 또는 회귀의 경우 실제 값에 매핑하려고 합니다. 이 알고리즘은 레이블이 지정된 대부분의 데이터와 정확히 일치할 수 있는 최상의 기능을 정의할 수 있을 때까지 많은 예제에서 실행됩니다. 그런 다음 레이블이 지정되지 않은 데이터를 실행하여 사람의 개입 없이 예측합니다. 다음과 같은 기능을 정의합니다.

그런 다음 기계 학습 알고리즘은 이러한 값을 클래스 집합을 나타내는 불연속 범위 또는 회귀의 경우 실제 값에 매핑하려고 시도합니다.

알고리즘은 대부분의 레이블이 지정된 데이터를 올바르게 일치시킬 수있는 최상의 기능을 정의 할 수있을 때까지 많은 예제로 실행됩니다. 그런 다음 사용자 개입없이 예측을하기 위해 레이블이 지정되지 않은 데이터를 통해 실행할 수 있습니다.

이것은 함수를 정의한다:

f:space of featurees -> classes =( discreate values or real values)

우리는 또한 분류를 다른 데이터 포인트 그룹을 분리하려는 과정(process)으로 생각할 수 있다

 기능을 정의하고 나면 데이터 세트의 전자 메일과 같은 예는 기능의 공간에서 각 지점이 다른 예 (또는 전자 메일)를 나타내는 지점으로 생각할 수 있습니다.

기계 알고리즘 작업은 비 스팸 전자 메일과 스팸을 분리하는 것과 같은 방식으로 다른 특성을 가진 지점을 분리하는 하이퍼 평면-hyper-plane (즉, 고차원 공간의 평면)을 그리는 것입니다.

아래 그림과 같이 2 차원의 경우에는 사소한 것처럼 보일 수 있지만 수백 또는 수천 차원의 예제에서는 매우 복잡 할 수 있습니다.

![선형회귀 1차]](C:\users\dlramcjf\Desktop\python\one plane)

이후 장에서 분류 또는 회귀 문제의 몇 가지 예를 살펴보겠습니다. 

이러한 문제 중 하나는 자릿수 분류입니다. 0부터 9까지를 나타내는 이미지 세트를 고려할 때 기계 학습 알고리즘은 각 이미지를 지정하는 숫자를 분류하려고 시도합니다. 

이러한 예에서, 우리는 가장 고전적인 데이터셋 중 하나인 MNIST 데이터셋을 사용할 것이다. 이 예에서는 각 자릿수가 28 x 28(=784) 픽셀의 영상으로 표시되며, 10자리 각각을 분류해야 하므로 784차원 공간에 9개의 분리된 하이퍼 평면을 그려야 합니다.

#h2 감독되지 않은 학습.

기계 학습 알고리즘의 두 번째 클래스는 감독되지 않은 학습(자율학습)이라고합니다. 이 경우 사전에 데이터에 레이블을 지정하지 않고 알고리즘을 결론 짓게합니다.

자율 학습의 가장 보편적이고 가장 단순한 예 중 하나는 클러스터링입니다.
이것은 데이터를 부분 집합으로 분리하려고 시도하는 기술입니다.

예를 들어 이전의 스팸/스팸이 아닌 메일의 경우 알고리즘은 모든 스팸 전자 메일에 공통되는 요소(예: 철자가 틀린 단어가 있음)를 찾을 수 있습니다.

이것이 무작위 분류보다 더 나은 분류를 제공할 수 있지만 스팸/비 스팸 메일이 그렇게 쉽게 분리될 수 있다는 것은 분명하지 않다. 

알고리즘이 데이터를 분리하는 부분 집합은 데이터 집합의 다른 클래스입니다. 클러스터링이 작동하려면 각 클러스터의 각 요소가 원칙적으로 클래스 내 유사성이 높고 다른 클래스와의 유사성이 낮아야합니다.

Clustering may work with any number of classes, and the idea behind clustering methods such as k-means is to find k-subsets of the original data whose elements are closer (more similar) to each other than they are to any other element outside their class. 

클러스터링은 원하는 수의 클래스에서 작동할 수 있으며, k-mean 과 같은
클러스터링 방법 개념은 다른 클래스보다 요소가 서로 더 가까운 원본 데이터의 k-subset을 찾는 것입니다.

물론, 이렇게 하기 위해서는 어떤 더 가깝거나 더 비슷한 의미를 정의할 필요가 있습니다. 즉, 포인트 사이의 거리를 정의하는 일종의 측정 기준을 정의해야 합니다.(예를 들어 선형관계..?)

--

![유한집합 클러스터링](./deep_picture/limitcluster.PNG)

![무한집합 클러스터링](./deep_picture/unlimitcluster.PNG)

클러스터링만이 자율학습이 아니며, 우리는 딥러닝의 최근 성공이 그것이 자율학습 테스크에서 매우 효과적이게 되는 것과 관련이 있다는 것을 알게 될 것이다.

새로운 데이터는 매우 빠르게 매일 생성되며, 모든 새 데이터에 라벨을 붙이는 작업은 상당히 힘들고 시간이 많이 소요됩니다.

자율학습 알고리즘의 장점 중 하나는 라벨이 붙은 데이터가 필요하지 않다는 것이다. 제한된 볼트만 머신(RBM)와 같은 감독되지 않은 심층 학습 기법 및 방법은 데이터에서 기능을 추출하여 작동합니다.

예를 들어, MNIST 데이터 세트를 사용하여 제한된 볼트만 시스템은 각 자릿수에 고유한 특성을 추상화하여 각 자릿수의 선과 원곡선의 모양을 탐지합니다.

자율학습은 데이터를 레이블에 매칭하는 것이 아니라 그에 따라 분류할 수 있는 숨겨진 구조를 드러냄으로써 작동합니다

또한, 예를 들어, 깊은 믿음의 그물을 가지고, 우리는 자율학습의 성능을 감독학습으로 정제함으로써 개선할 수 있다.

** 추가적인 검색으로 인한 자료

이때 RBM이란.확률적으로 순환하는 신경망 네트워크이다.

![볼츠만 머신](./deep_picture/Boltman.PNG)
볼츠만 머신(Boltzmann machine)은 볼 수 있는 층(visible layer)과 숨겨진 층(hidden layer)의 두 층으로 구성된 그래픽 모델이다. 그런데 이 모델에서 각 볼 수 있는 유닛은 숨겨진 유닛들과만 연결되고, 볼 수 있는 유닛들 사이에 그리고 숨겨진 유닛들 사이에는 서로 연결이 없을 때 이를 제한된 볼츠만 머신(RBM: restricted Boltzmann machine)이라 한다

**

#h2 강화학습(Reinforcement learning )

기계 학습 기술의 세 번째 클래스는 강화 학습이라고합니다.

이는 성능 향상을 위해 피드백 요소를 사용하지만 감독학습과는 다르게 작동합니다. 

강화 학습 기법의 일반적인 적용은 게임을 하는 방법을 기계들에게 가르치는 것이다: 이 경우, 우리는 각각의 움직임을 좋거나 나쁘다고 지칭하지 않지만, 피드백은 게임의 결과나 게임 중 신호를 통해 이루어진다, 득점이나 실점과 같은

게임에서 이기는 것은 올바른 숫자를 인식하거나 전자 메일이 스팸인지 아닌지와 같은 긍정적인 결과를 반영하는 반면, 게임에서 진다면 더 많은 "학습"을 필요로 할 것이다. 

강화 학습 알고리즘은 게임에서 승리하는 것과 같은 성공적인 결과를 가져온 과거에 시도 된 행동을 재사용하는 경향이 있습니다. 그러나 미지의 영역에서 알고리즘은 결과에 따라 게임의 구조를 더 깊이 배울 수있는 새로운 동작을 시도해야합니다.

일반적으로 행동은 상호 관련이 있기 때문에 "좋음"또는 "나쁨"으로 평가 될 수있는 단일 행동이 아니라 함께 평가되는 행동의 전체적 역학이다.

Similar to how in playing chess sometimes sacrificing a pawn may be considered a positive action if it brings a better positioning on the chessboard, even though the loss of a piece is, in general, a negative outcome, in reinforcement learning it is the whole problem and its goal that is explored.

체스를 하는 것과 비슷하다. 때로는 폰을 희생시키는 것이 일반적으로 부정적인 결과인데도 체스판에서 더 나은 위치를 가져오는 것 처럼. 비록 한 조각의 손실이 일반적으로 강화 학습에서 부정적인 결과이지만 더 나은 위치를 가져오면 긍정적인 행동으로 간주될 수 있습니다.??

예를 들어, 움직이는 청소 로봇은 방을 계속 청소할지 또는 충전소로 다시 이동 할지를 결정해야 할 수도 있습니다.

그러한 결정은 유사한 상황에서 배터리가 소진되기 전에 충전소를 찾을 수 있었는지 여부에 기초하여 이루어질 수있다.

강화 학습에서 기본 아이디어는 최종적으로 얻는 보상이다. 알고리즘은 알고리즘이받는 총 보상을 최대화하기 위해 노력합니다.

보강 학습의 간단한 예제를 사용하여 tic-tac-toe의 고전 게임을 즐길 수 있습니다. 이 경우 보드의 각 위치는 이전 경험을 토대로 그 주에서 게임을 승리 할 확률 인 확률 (값)과 관련이 있습니다.

처음에는 각 위치의 승률 상태가 50 %로 설정되어 있습니다. 이는 처음에는 어느 위치에서나 승리 할 확률이 동일하다고 가정합니다.

일반적으로 기계는 게임에서 이기기 위해 더 높은 값을 가진 위치로 이동하려고 시도하고, 대신에 잃는다면 다시 평가할 것입니다. 각 위치에서 기계는 고정 된 결정된 규칙보다는 가능한 결과에 따라 선택합니다. 계속해서 플레이 할 때,이 확률은 정교 해지고 위치에 따라 성공 확률이 더 높거나 낮을 것입니다.

--

## 기계 학습 시스템에 관련된 단계

지금까지 우리는 서로 다른 기계 학습 접근 방식에 대해 논의했으며, 세 가지 다른 클래스로 대략 정리했습니다.

고전 기계 학습의 또 다른 중요한 측면은 당면의 문제를 더 잘 이해할 수 있도록 데이터를 이해하는 것입니다. 기계 학습을 적용하기 위해 정의해야 할 중요한 측면은 대략 다음과 같이 설명 할 수 있습니다.

• 학습자 : 이것은 사용되는 알고리즘과 "학습 철학"을 나타냅니다. 다음 단락에서 볼 수 있듯이 서로 다른 학습 문제에 적용 할 수있는 여러 가지 다양한 기계 학습 기술이 있습니다. 여러 가지 문제가 특정 기계 학습 알고리즘에 더 적합 할 수 있으므로 학습자를 선택하는 것이 중요합니다.
• 트레이닝 데이터 : 우리가 관심을 갖고있는 원시 데이터 세트입니다. 이러한 데이터는 자율 학습을 위해 레이블이 지정되지 않거나 감독 학습을위한 레이블을 포함 할 수 있습니다. 학습자가 문제의 구조를 이해할 수 있도록 충분한 샘플 데이터를 갖는 것이 중요합니다.

• 표현: 학습자가 데이터를 수집할 수 있도록 선택한 형상의 측면에서 데이터를 표현하는 방법입니다. 예를 들어 이미지를 사용하여 숫자를 분류하려는 경우 이는 이미지의 픽셀을 설명하는 값의 배열을 나타냅니다. 더 나은 결과를 얻기 위해서는 데이터 표현을 잘 선택하는 것이 중요하다.

• 목표: 이는 당면한 문제에 대한 데이터에서 배워야 하는 이유를 나타냅니다. 이는 대상과 엄격히 관련되어 있으며 학습자가 어떤 방법을 사용해야 하는지, 어떤 표현을 사용해야 하는지 정의하는 데 도움이 됩니다. 예를 들어, 원치 않는 이메일의 우편함을 정리하는 것이 목표일 수 있으며, 목표는 스팸 메일 탐지 등과 같은 학습자의 목표가 무엇인지 정의합니다.

•대상: 학습 대상과 최종 출력을 나타냅니다. 라벨링되지 않은 데이터의 분류일수 있으며, 숨겨진 패턴이나 특성에 따라 입력 데이터를 나타낼 수 있으며,향후 예측을 위한 시뮬레이터일 수 있으며, 외부 자극에 대한 반응일 수 있다. 
강화 학습의 경우 전략이 될 수 있습니다.

어떠한 기계 학습 알고리즘도 완벽한 수치 설명이 아니라 대상의 근사치만 달성할 수 있다. 이것은 아무리 강조해도 지나치지 않습니다.

기계 학습 알고리즘은 문제에 대한 정확한 수학적 해결책이 아니라 단지 근사치일 뿐이다.

이전 단락에서 우리는 학습이 특징(입력)의 공간에서부터 다양한 범위의 클래스로 정의했습니다.

우리는 나중에 신경 네트워크와 같은 특정 기계 학습 알고리즘이 이론적으로 어느 정도의 기능을 근사시킬 수있는 것으로 입증 될 수 있음을 알게 될 것입니다.

이 정리를 보편적 근사 이론(Universal Approximation Theorem)이라고 부르지 만, 문제에 대한 정확한 해결책을 얻을 수 있다는 것을 의미하지는 않습니다. 또한 문제에 대한 해결책은 트레이닝 데이터를 더 잘 이해함으로써 더 잘 달성 될 수 있습니다.

일반적으로 고전적인 기계 학습 기술로 해결할 수있는 문제는 전개 전에 교육 데이터를 철저하게 이해하고 청소해야 할 수 있습니다.기계 학습 문제에 접근하는 데 필요한 몇 가지 단계를 설명해야 하는 경우 다음과 같이 요약할 수 있습니다.

• 데이터 수집 : 가능한 한 많은 데이터를 수집하고 감독 학습문제에서 올바른 라벨링을 의미합니다.

• 데이터 처리 : 데이터 정리 (예 : 중복되거나 고도로 연관된 기능 제거 또는 누락 된 데이터 채우기)와 교육 데이터를 정의하는 기능에 대한 이해를 의미합니다.

• 테스트 케이스 생성 : 일반적으로 데이터는 2 개 또는 3 개의 세트로 나눌 수 있습니다 : `알고리즘을 교육하는 훈련 데이터` 세트, 알고리즘을 훈련 한 후 접근 방식의 `정확성을 테스트하는 테스트 데이터` 세트

또한 종종 검증 데이터셋을 만들어 교육 테스트 절차를 여러 번 반복하고 결과에 만족한 후 최종 테스트(또는 검증)를 수행하는 경우가 있습니다.

테스트 및 검증 데이터셋을 생성해야 하는 타당한 이유가 있습니다. 앞서 언급했듯이 기계 학습 기법은 원하는 결과의 근사치만 생성할 수 있습니다. 

이것은 종종 유한하고 제한된 수의 변수 만 포함 할 수 있으며 우리 자신의 통제 밖에있는 많은 변수가있을 수 있기 때문입니다.

단일 데이터 세트 만 사용한 경우 우리 모델은 데이터를 "암기"하게되고 암기 한 데이터에 매우 높은 정확도의 값을 생성 할 수 있지만이 결과는 다른 유사한 데이터 세트에서 재현되지 않을 수 있습니다.

기계 학습 기술의 핵심 목표 중 하나는 일반화 능력입니다.

이것이 교육 후에 모델 선택을 튜닝하는 데 사용되는 테스트 데이터 세트와 선택한 알고리즘의 유효성을 확인하기 위해 프로세스 마지막에만 사용되는 최종 유효성 검사 데이터 세트를 모두 만드는 이유입니다.

데이터에서 유효한 피쳐를 선택하는 중요성과 데이터를 "외우는 것"을 피하는 중요성을 이해하기 위해 (보다 기술적 인 측면에서 이것은 문헌에서 "오버 피팅 (overfitting)"이라고 불리는 것이며, 이것이 우리가 호출 할 것입니다 지금부터) xkcd 만화에서 가져온 농담을 예로 들어 보겠습니다.

"1996년 이전에는 현직이고 전투 경험이 없는 민주적인 미국 대통령 후보가 스크래블에서 더 가치가 있는 이름을 가진 사람을 이긴 적이 없었습니다." 

이 예에서 그러한 "규칙"은 의미가 없지만 유효한 특징을 선택하는 중요성을 강조합니다 (Scrabble에서 이름이 얼마나 가치가 있으며 미국 대통령 선출과 관련이 있습니까?). 예측자들은 현재의 데이터를 예측할 수는 있지만 보다 일반적인 데이터의 예측 자로 사용될 수는 없으며 52 개의 선거에 대해 이것이 실현되었다는 사실은 단순한 우연이었다.

이것은 일반적으로 오버 피팅 (overfitting)이라고 불리는 것입니다. 즉, 손에있는 데이터를 완벽하게 맞추는 예측을 수행하지만 더 큰 데이터 세트로 일반화하지는 않습니다. 오버 피팅은 일반적으로 "소음"(즉, 실제 의미가없는 정보)을 인식하고 모델을 작은 동요,흔들림에 맞추려 고 노력하는 과정입니다.

또 다른 예는 기계 학습을 사용하여 지상에서 다시 땅에 닿을 때까지 (수직이 아닌) 지상에서 던져진 공의 궤도를 예측하려고 시도 할 수 있습니다.

물리학은 궤도가 포물선 모양이라는 것을 우리에게 가르쳐 주며, 수천 개의 그런 던짐을 관찰하는 훌륭한 기계 학습 알고리즘이 해결책으로 포물선을 생각해 낼 것으로 기대합니다.

하지만, 만약 우리가 공을 확대해서 난기류로 인한 공기 중에서 가장 작은 변동을 관찰한다면, 우리는 공이 일정한 궤적을 가지고 있지 않지만 작은 동요를 일으킬 수 있다는 것을 알 수 있다. 이것이 우리가 "소음"이라고 부르는 것이다. 

이러한 작은 혼란을 모델링하려고 시도하는 기계 학습 알고리즘은 큰 그림을 보지 못하고 만족스럽지 못한 결과를 낳습니다. 

다시 말해, overfitting은 기계학습 알고리즘이 나무를 보지만 숲은 잊게 만드는 과정이다.

![오버피팅](./deep_picture/overfitting.PNG)


테스트 데이터의 정확도가 교육 데이터에 대해 달성된 결과와 비슷하지 않다면 모델을 오버피딩했다는 것을 알 수 있습니다. 따라서 교육 데이터를 테스트 데이터와 구분합니다.

물론, 우리는 반대의 오류를 만들지 말아야합니다. 즉, undefit the model,
undefit=샘플 크기에 비해 매개 변수가 너무 적은 통계 모델을 사용하는것.

`샘플 크기에 비해 매개 변수가 너무 적은 모델을 쓰지 말라 이거다.`

실제로 우리의 훈련 데이터에서 가능한 한 정확하게 예측 모델을 만드는 것을 목표로한다면 underfitting은 overfitting보다 훨씬 위험이 적으므로 모델을 초과 적용하지 않도록 대부분의 주의가 필요합니다.

+오버피팅보단 언더피팅이 낫다.

![언더피팅](./deep_picture/underfitting.PNG)

---

## 인기있는 기술 / 알고리즘에 대한 간략한 설명

"학습 스타일", 즉 책 초반에 논의 된 세 가지 수업, 감독 학습, 감독되지 않은 학습 및 강화 학습을 기반으로 알고리즘을 그룹화하는 것 외에도 구현별로 그룹화 할 수도 있습니다.

위에서 논의한 각 클래스는 서로 다른 기계 학습 알고리즘을 사용하여 구현될 수 있습니다. 예를 들어, 각기 다른 감독 학습 기법을 사용할 수 있습니다. 각 학습 기법이 당면한 특정 분류 또는 회귀 작업에 가장 적합할 수 있습니다.

실제로, 분류와 회귀를 구별하는 것이 가장 중요하며, 우리가 달성하고자하는 것을 이해하는 것이 중요합니다.

다음은 각 기계 학습 방법에 대한 철저한 설명이나 철저한 설명을 의미하는 것은 아니며, 독자는이를 Python Machine Learning, Sebastian Raschka (https://www.packtpub.com/ big- 데이터 및 비즈니스 인텔리전스 / 파이썬 기계 학습), 오히려 독자들에게 다양한 기술의 단순한 맛을 제공하고 깊이있는 학습이 다른 기술과 얼마나 다른지에 대한 간단한 검토를 의미합니다.

다음 장에서는 심층 학습이 단순히 알고리즘을 학습하는 것이 아니라 고전적인 기계 학습 기술과 크게 다르다는 것을 알게 될 것입니다.

회귀 알고리즘, 선형 회귀, 고전 분류기같은 의사결정 트리, 나이브 베이즈 , 지원벡터 머신, 자율 클러스터링 알고리즘 같은 k-mean, 강화 학습 기술, 크로스 엔트로피 방법 등을 도입하여 존재하는 기계 학습 기술의 다양성을 조금 엿볼 수 있으며, 신경망을 도입하여 이 목록을 끝낼 것입니다. 이것이 책의 주안점입니다.

--

## 선형회귀(Linear regression )

회귀 알고리즘은 크기, 나이, 욕실 수, 층 수, 위치 등과 같은 특정 기능이있는 집의 비용과 같이 가치를 예측하기 위해 입력 데이터의 기능을 사용하는 감독 알고리즘의 일종입니다.

회귀 분석은 입력 데이터 집합에 가장 잘 맞는 함수의 매개 변수 값을 찾으려고 시도합니다.선형 회귀 알고리즘에서 목표는 목표 값에 가장 근접한 입력 데이터에서 함수에 대한 적절한 매개 변수를 찾아서 비용 함수를 최소화하는 것입니다.

비용 함수는 정확한 결과를 얻지 못하는 정도의 오류 함수입니다. 사용되는 일반적인 비용 함수는 평균 제곱 오차이며, 여기서 예상 값과 예측 결과의 차이를 제곱한다. 모든 입력 예제에 대한 합계는 알고리즘 오류를 제공하고 비용 함수를 나타냅니다.

25 년 전에 건축 된 100 평방 미터의 집이 3 개의 욕실과 2 개 층으로 구성되어 있다고 가정 해보십시오.

  또한 집이 10 개의 다른 지역에있는 도시를 1에서 10까지의 정수로 나눈 다음이 집이 7로 표시된 지역에 있다고 가정합니다. 그러면이 집을 다음과 같이 매개 변수화 할 수 있습니다. 5 차원 벡터 x = (100, 25, 3, 2, 7). 이 집이 € 10,0000의 예상 가치를 가지고 있음을 또한 알았다고 가정 해보십시오. 우리가 원하는 것은 f (x) = 100000과 같은 함수 f를 생성하는 것입니다.

선형 회귀 분석에서 이것은 100 * w1 + 25 * w2 + 3 * w3 + 2 * w4 + 7 * w5 = 100000이되도록 벡터 w = (w1, w2, w3, w4, w5)

 우리가 천개의 집을 가지고 있다면, 모든 집에 동일한 과정을 반복 할 수 있고 이상적으로는 모든 집에 대해 정확한 값을 예측할 수있는 벡터를 찾고 싶습니다. 우리가 초기에 임의의 w 값을 선택했다고합시다.

이 경우 f (x) = 100 * w1 + 25 * w2 + 3 * w3 + 2 * w4 + 7 * w5가 1,00,000과 같지 않을 것으로 예상 할 수 있습니다.

->w가 정확할리 없기 때문이지.

따라서 Δ = (100000 - f (x)) 2의 오차를 계산할 수 있습니다. 이것은 하나의 예제 x에 대한 제곱 오차이고, 모든 예제에 대한 모든 제곱 오차의 평균은 우리의 비용, 즉 우리의 함수가 실제 값과 얼마나 다른지를 나타냅니다. 

->왜 /2지?  

그러므로 우리의 목표는이 오차를 최소화하는 것이며, 이렇게하기 위해 우리는 w에 대한 비용 함수의 미분 δ를 계산한다

미분은 함수가 증가하거나 감소하는 방향을 나타냅니다.

therefore, moving w in the opposite direction to the derivative will improve our function's accuracy. 

따라서 미분을 반대방향으로 이동한다면 함수의 정확도가 향상된다.

이것은 선형 회귀의 주요 포인트로, 오류를 나타내는 비용 함수의 최소 값으로 이동합니다.

물론 미분은 방향을 나타낼 뿐이기 때문에 미분 방향으로 얼마나 빨리 움직이고 싶은지는 결정해야 한다.

비용함수는 선형이 아니므로, 따라서 우리는 미분이 지시하는 방향으로 작은 단계 만을 취할수 있도록 해야한다.

너무 큰 발걸음을 내딛는 것은 우리가 최소한을 초과하게 만들 수 있고, 따라서 그것에 집중하지 못할 수도 있다.

이 단계의 크기는 학습 속도라고 불리는 것이며, 우리는 기호 "lr"로 크기를 나타낼 수 있습니다.

따라서 w = w - δ * lr을 설정함으로써보다 나은 솔루션을 향한 w의 선택을 향상시킵니다.

-왜 곱하는지 이해는 불가. 오차를 줄여 가장 가까운 w값을 만들려는건 알겠는데..

이 과정을 여러 번 반복하면 함수 f에 대한 최선의 선택을 나타내는 w 값이 생성됩니다.

여기서 강조할 점은, 이 프로세스 로컬에서만 작동하며 공간이 볼록하지 않은 경우 전역적인 최상의 가치를 찾지 못할 수도 있음

이미지가 암시 하듯이, 많은 로컬 미니 마가 존재한다면, 알고리즘은 이러한 로컬 미니 마 중 하나에 갇히게 될 수 있으며,에러 함수의 글로벌 최소값에 도달하기 위해 그것을 벗어날 수 없습니다.

 마치 작은 공이 산에서 내려 오다가 작은 계곡에 갇히고 결코 산의 바닥에 닿을 수는 없는 것처럼.




![그래프](./deep_picture/minima.PNG)

상단 그래프는 볼록형이므로 하나의 최소값 만 존재합니다. 아래 그래프에서 함수는 두 개의 로컬 미니 마를 가지므로 초기화에 따라 프로세스가 전역 최소가 아닌 첫 번째 로컬 최소값을 찾을 수 있습니다.

--
## 결정트리(Decision trees )

널리 사용되는 또 다른 감독 알고리즘은 의사 결정 트리 알고리즘입니다.

의사 결정 트리 알고리즘은 "트리"형태로 분류자를 생성합니다.

의사 결정 트리는 특정 속성에 대한 테스트가 수행되는 결정 노드와 대상 속성의 값을 나타내는 리프 노드로 구성됩니다.

의사결정 트리는 루트 노드(맨위)에서 시작하여 리프 노드(맨아래)에 도달할 때까지 의사결정 노드를 통해 아래로 이동하는 분류자의 한 유형이다

이 알고리즘의 대표적인 적용 분야는 아이리스 꽃 데이터 세트(http://archive. ics.uci.edu/ml/datasets/Iris)이며, 세 가지 유형의 아이리스(Iris setosa, Iris Virinica, Iris vericor) 중 50개 표본의 데이터가 포함되어 있습니다.

데이터 세트를 만든 로널드 피셔 (Ronald Fisher)는이 꽃들의 네 가지 다른 특징,꽃의 길이와 너비, 꽃잎의 길이와 너비를 측정했습니다.

여기서 우리는 정확하게 분류 할 수있는 단순화 된 의사 결정 트리를 설명 할 것입니다. 거의 모든 꽃은 꽃잎의 길이와 너비 중 두 가지를 사용합니다.

첫 번째 노드부터 시작하여 꽃잎 길이에 대한 첫 번째 테스트를 만듭니다.

만약 꽃잎 길이가 2.5보다 작다면, 꽃은 아이리스 세토사 종에 속합니다

사실 이것은 모두 꽃잎 길이가 2.5cm 미만인 모든 세토사 꽃들을 정확하게 분류합니다. 그러므로, 우리는 결과 Iris setosa에 의해 분류 된 잎 노드에 도달한다.

꽃잎의 길이가 2.5보다 큰 경우 다른 분기를 가져 와서 새 결정 노드에 도달하고 꽃잎의 너비가 1.8보다 큰지 여부를 테스트합니다.

꽃잎의 너비가 1.8보다 크거나 같으면 우리는 잎 노드에 도달하고 우리는 꽃을 아이리스 버지니아라고 분류합니다. 그렇지 않으면 꽃잎의 길이가 4.9보다 긴지 여부를 다시 테스트하는 새로운 결정 노드에 도달합니다.

그렇다면 Iris virginica 꽃으로 표시된 잎 노드에 도달합니다. 그렇지 않으면 Iris versicolor 꽃으로 표시되는 다른 잎 노드에 도달합니다.

논의 된 결정 트리는 왼쪽 노드가 결정 노드에서의 테스트에 대한 긍정적 인 대답을 반영하는 반면, 오른쪽 분기는 결정 노드에서의 테스트에 대한 부정적인 응답을 나타냅니다.각 분기의 끝 노드는 리프 노드입니다.

![결정트리]./deep_picture/divisiontree.PNG)

이 예는 의사 결정 트리 알고리즘이 선형 회귀와 얼마나 다른지를 보여줍니다. 또한, 신경망을 도입 할 때 독자는이 동일한 데이터 집합을 사용하여 신경망의 작동 방식을 볼 수 있습니다. 이 예제에서 우리는 파이썬 코드도 제공 할 것이고 신경망이 그들의 특징에 따라 꽃을 어떻게 분리하려고하는지 몇 가지 그림을 보여줄 것입니다.

---

#h2 K-means

이미 설명한 클러스터링 알고리즘은 감독되지 않은 기계 학습 방법의 한 유형입니다.

가장 일반적인 클러스터링 기법은 k-means 클러스터링 (k-means clustering)이라고 불리는 클러스터링 기법으로 데이터 집합의 모든 요소를 k 개의 고유 한 하위 집합으로 그룹화하여 클러스터링하는 기술입니다 (따라서 이름의 k).

K-means는 상대적으로 간단한 과정이며, k 개의 부분 집합의 중심을 나타내는 무작위 k 점을 선택하는 것으로 구성되며,이 무작위점을 sentriod(중심)이라고합니다.

그런 다음 각 중심에 대해 가장 가까운 모든 점을 선택합니다. 그러면 k 개의 다른 하위 집합이 만들어집니다. 이 시점에서 각 하위 집합에 대해 센터를 다시 계산합니다.

우리는 다시 새로운 중심을 가지고 있습니다. 그리고 우리는 위의 단계를 반복하여 각각의 중심에 가장 가까운 지점의 새로운 부분인 중심을 선택합니다. 우리는 중심이 움직이지 않을 때까지 이 과정을 계속합니다.

->여기서 중심부란 sentriod임.

이 기법을 제대로 사용하려면 점 사이의 거리를 계산할 수있는 척도를 식별 할 수 있어야합니다. 이 절차는 다음과 같이 요약 할 수 있습니다.

1. centroids라고 불리는 초기 k- 점을 선택하십시오.
2. 데이터 세트의 각 점에 가장 가까운 중심을 연결합니다.
3. 특정 중심에 연결된 점 세트에 대한 새 중심을 계산합니다.
4. 새로운 중심을 새로운 중심으로 정의하십시오.
5. 중심이 움직이지 않을 때까지 3 단계와 4 단계를 반복하십시오.


이 방법은 임의의 centriods(중앙점)의 초기 선택에 민감하며, 다른 초기 선택(다른 임의의 중앙점을 다시 선택한다.)에 대해 과정을 반복하는 것이 좋은 생각일 수 있다는 점에 유의해야 한다.

또한 일부 중심점이 데이터 집합의 어떤 점에도 가장 가까이 있지 않는다면, 하위 집합의 수를 k 개에서 줄이는 것이 가능합니다.

만약 우리가 위 예에서 k=3과 함께 k-means를 사용한다면, 그것은 또한 언급할 가치가 있다. 

의사결정 트리를 사용하여 발견한 홍채 데이터 세트에 대해 동일한 분류를 얻지 못할 수 있습니다. 이것이 각 문제에 대해 올바른 기계 학습 방법을 선택하고 사용하는 것이 얼마나 중요한지를 한 번 더 강조합니다.

이제 k-means 클러스터링을 사용하는 실용적인 예제를 살펴 보겠습니다.

피자 배달 장소가 신도시에 4 개의 프랜차이즈를 개설하기를 원하며 4 개의 새 사이트의 위치를 선택해야한다고 가정 해 봅시다.

이것은 k-means 클러스터링을 사용하여 쉽게 해결할 수있는 문제입니다.

아이디어는 피자가 가장 자주 주문되는 위치를 찾는 것입니다. 이들은 우리의 데이터 포인트가 될 것입니다. 다음으로 사이트 위치가있는 4 개의 임의 지점을 선택합니다.

k-means 클러스터링 기법을 사용하여 나중에 각 배달 장소까지의 거리를 최소화하는 4 개의 최적 위치를 식별 할 수 있습니다. 이것은 k-means 클러스터링이 비즈니스 문제를 해결하는 데 도움이 될 수있는 예입니다.

![ㅏals](C:\Users\dlrmacjf\Desktop\python>k-means)

#h2 나이브베이즈(Naïve Bayes )

Naive Bayes는 다른 많은 기계 학습 알고리즘과 다릅니다.

확률 론적으로, 대부분의 기계 학습 기술이 평가하려고 시도하는 것은 어떤 이벤트 Y가 주어진 조건 X의 확률이다. 우리는 p (Y | X)로 표시한다.

  예를 들어 숫자를 나타내는 그림 (즉, 특정 픽셀 분포를 갖는 그림)이 주어진다면 해당 숫자가 5 일 확률은 얼마입니까?

픽셀의 분포가 5로 표시된 다른 예제의 픽셀 분포에 가깝게되는 경우 해당 이벤트의 확률이 높습니다. 그렇지 않으면 확률이 낮습니다.

때때로 우리는 반대의 정보를 가지고 있습니다. 즉, 우리는 사건 Y를 가지고 있다는 것을 알고, 우리의 표본이 X라는 확률을 압니다. 나이브베이즈 정리는 다음과 같이 말합니다 :

p (X | Y) = p (Y | X) * p (X) / p (Y)

여기서 p (X | Y)는 Y가 주어진 인스턴스 X를 생성 할 확률을 의미하며, 이 때문에 naive bayes를 생성 적 접근이라고합니다.

In simple terms, we may calculate the probability that a certain pixel configuration represents the number 5, knowing what is the probability, given that we have a 5, that a random pixel configuration may match the given one. 

간단히 말하자면, 임의의 픽셀 구성이 5를 나타내는 확률을 계산할 수 있으며, 주어진 확률이 5임을 알면 임의의 픽셀 구성이 주어진 픽셀 구성과 일치 할 수 있습니다.

이것은 의료 검사의 영역에서 가장 잘 이해됩니다.

우리가 특정한 질병이나 암을 검사한다고 가정해보자. 우리는 우리의 테스트 결과가 긍정적이라는 것을 고려할 때 우리가 특정한 질병에 걸릴 확률을 알고 싶다.

현재, 대부분의 테스트는 신뢰성 값을 가지고 있는데, 이것은 특정 질병에 걸린 사람들을 대상으로 시행될 때 양성 반응을 보일 확률의 백분율입니다.

p (X | Y) = p (Y | X) * p (X) / p (Y)를 반대로하면,우리는 그것을 가지고 있습니다 :

p(cancer | test=positive) = p(test=positive | cancer) * p(cancer)/p(test=positive) 

검사는 98 % 신뢰도가 있다고 가정합니다. 즉, 환자의 98 %가 암을 앓고 있으면 검사는 양성이며, 마찬가지로 암이없는 사람도 검사 결과가 부정적입니다.

또한이 특별한 종류의 암은 노인들에게만 영향을 미친다고 가정합니다.

50 세 미만의 사람들 중 2 %만이 이런 종류의 암을 앓고 있으며 50 세 이하의 사람들에게 시행되는 검사는 인구의 3.9 %에서만 긍정적입니다 (우리는이 사실을 데이터에서 파생시킬 수 있었지만 간단하게하기 위해 정보를 제공했습니다)

우리는 이 질문을 할 수 있습니다 : 검사가 암에 대해 98 % 정확하고 45 세의 사람이 검사를 받았고 그것이 양성으로 밝혀지면 암에 걸릴 확률은 얼마입니까? 위 공식을 사용하여 계산할 수 있습니다.

p(cancer | test=positive) = 0.98 * 0.02/0.039 = 0.50

따라서, 테스트의 높은 정확성에도 불구하고, Nayve Bayes는 50세 미만에서는 암이 매우 드물다는 사실을 고려할 필요가 있다고 말합니다. 따라서 테스트의 양성이 98%의 확률을 제공하지 못합니다.

일반적으로 추정하려는 결과에 대한 확률 p(cancer) 또는 그 이상의 확률을 사전 확률이라고 합니다. 추가 정보가 없는 사건의 확률을 나타내기 때문입니다.그러므로 우리가 테스트를 보기전에

이 시점에서 우리는 더 많은 정보가 있다면 어떻게 될지 궁금해 할 것입니다.

예를 들어 우리가 다른 신뢰도로 다른 검사를 수행하거나 가족의 암 재발과 같은 사람에 대한 정보를 알고 있다면.

위의 방정식에서 우리는 계산의 요인 중 하나 인 확률 p (test = positive | cancer)를 사용했습니다.

그리고 두 번째 검사를 실시하고 그것이 양성으로 확인되면, 우리는 또한 p (test2 = positive | cancer)을 가질 것입니다.

naive bayes는 각 정보가 서로 독립적이라는 가정을 만든다.(즉, 테스트 2는 테스트 1의 결과를 알지못했고, 독립적이라는 것이다. 이 뜻은, 테스트1은 테스트2의 결과를 바꿀수 없었고 그렇기에 첫번째 테스트의 결과는 편향되지 않았다.)

  naive Bayes는 서로 다른 사건의 독립성을 추정하여 그 확률을 계산하는 분류 알고리즘입니다. 그래서:

p(test1 and test2=pos | cancer) =p(test1=pos | cancer)*p(test2=pos | cancer)

이 방정식은  가능성 L?(likelihood L)이라고도하며, (test1 및 test2 = pos) 사람이 암에 걸렸다는 사실을 감안할 때 test1 및 test2가 양성인 것으로 나타납니다.

p(cancer | both tests=pos) = = p(both test=pos | cancer)*p(cancer)/p(both tests=pos)  = = p(test1=pos | cancer)*p(test2=pos | cancer) *p(cancer)/p(both tests=pos) 


--

#h2 보조벡터머신(Support vector machines)

지원 벡터 기계는 주로 분류에 사용되는 지도 기계 학습 알고리즘입니다.

다른 머신 학습 알고리즘에 비해 지원 벡터 머신의 장점은 데이터를 클래스로 분리 할뿐만 아니라 최대화하는 분리 하이퍼 평면 (3 차원 이상의 공간에서 평면과 유사)(the analog of a plane in a space with more than three dimensions) 을 찾는 것입니다.

각 점을 하이퍼 평면으로부터 분리하는 margin(여백), 또한 지원 벡터 머신은 데이터가 선형으로 분리되지 않는 경우에도 처리 할 수 있습니다.

비선형으로 분리 가능한 데이터를 처리하는 두 가지 방법이 있습니다. 하나는 부드러운 여백을 도입하는 것이고 다른 하나는 소위 커널 트릭을 도입하는 것입니다.

부드러운 여백은 알고리즘의 예측 가능성을 유지하면서 몇 가지 분류되지 않은 요소를 허용함으로써 작동합니다.

소프트 마진은 알고리즘의 예측 가능성을 유지하면서 몇 가지 분류되지 않은 요소를 허용함으로써 작동합니다.

위에 설명했듯이, 실제로는 기계 학습 모델을 과도하게 조율하지 않는 것이 더 좋으며, 지원 벡터 머신 가설 중 일부를 완화하여 수행 할 수 있습니다.

커널 트릭은 대신 피처 공간을 다시 하이퍼 평면이 아닌 하이퍼 평면을 정의 할 수있는 또 다른 공간으로 피처 공간을 매핑하는 작업을 포함하며, 분리 가능한 것으로 보이지 않는 데이터 세트의 요소를 분리 할 수 ​​있습니다.

너무 많은 시간이 걸리 겠지만 벡터 시스템을 지원한다는 개념이 비선형 상황으로 일반화 할 수있는 능력으로 인해 매우 인기 있고 효과적이라는 개념을 강조하고 싶습니다.

우리가 전에 보았 듯이, 감독 된 기계 학습 알고리즘의 임무는 피처 공간에서 일련의 클래스에 이르는 함수를 찾는 것입니다.

각 입력 x = (x1, x2, ..., xn)은 입력 예제를 나타내고 각 \\({x}_i\\)는 \\({i}^th\\) 기능의 x 값을 나타냅니다.

 \\({i}^th\\) 기능이 욕실 수와 일치하면  \\({x}_i\\)는 집 x에있는 욕실 수에 해당합니다.

 이전에 우리는 욕실이나 위치의 수와 같은 일부 기능에 따라 특정 주택의 재판매 가치를 추정하려고 시도했습니다.

우리는 함수 k를 만들수있고 기능 K는 기능 공간에서 이 공간의 다른 표현까지 생성할 수 있습니다. 커널이라고 불리는.

예를 들어, k는 \\({x}_i\\)를 \\({x}_i\\) 2로 맵핑하고, 일반적으로 기능 공간을 다른 공간 W에 비선형 적으로 맵핑 할 수있다.

따라서 분리된 w의 하이퍼 평면은 더 이상 선형 하이퍼 평면이 아닌 기능 공간으로 다시 매핑 될 수 있습니다.'

이것이 사실 인 정확한 조건은 잘 정의되어 있지만이 짧은 소개의 범위를 벗어납니다.

그러나 이는 다시 고전 기계 학습 알고리즘에서 올바른 기능을 선택하는 중요성을 다시 한번 강조하며, 특정 문제에 대한 해결책을 찾는 데 도움이 될 수 있습니다.

![서포트벡터](./deep_picture/supportvector.PNG)

왼쪽에는 커널이 적용되기 전에 비선형으로 분리 가능한 세트가 있습니다. 오른쪽은 커널이 적용된 후 동일한 데이터 세트이고 데이터는 선형으로 분리 될 수 있습니다


--


#h2 교차 엔트로피 기법(cross-entropy method)

지금까지 우리는 지도및 non-지도 학습 알고리즘을 소개했다.

교차 엔트로피 방법은 그대신 알고리즘의 강화 학습 클래스에 속하며, 이에 대해서는 7 장, 8장에선 보드 게임에 대한 딥러닝, 책의 컴퓨터 게임에 대한 딥러닝을 자세히 설명합니다.

십자형 방법은 최적화 문제를 해결하는 기술, 즉 특정 기능을 최소화하거나 최대화하기위한 최상의 매개 변수를 찾는 기술입니다.

1. 딥 러닝을 위해 최적화하려는 변수의 랜덤 표본을 생성합니다. 이러한 변수는 신경 네트워크의 가중치일 수 있다.
2. 태스크를 실행하고 성능을 저장하십시오.
3. 최적의 실행을 확인하고 가장 실적이 좋은 변수를 선택하십시오.
4. 실적이 가장 우수한 실행을 기반으로 각 변수의 새로운 평균과 분산을 계산하고 변수의 새 샘플을 생성합니다.
5. 정지 조건에 도달하거나 시스템이 개선되지 않을 때까지 단계를 반복하십시오

많은 변수에 따라 달라지는 함수에 대해 해결하려고 한다고 가정하자.

예를 들어, 우리는 특정 고도에서 발사되었을 때 가장 오래 날 수 있는 모형 비행기를 만들기 위해 노력하고 있다.

비행기가 커버하는 거리는 날개 크기, 각도, 무게 등의 기능이 될 것이다. 매번, 우리는 각 변수를 기록하고 비행기를 띄우고 그것이 날아가는 거리를 측정할 수 있다.

그러나 가능한 모든 조합을 시도하기보다는 통계를 작성하고 최우선 및 최악의 실행을 선택하며 최적의 실행 과 최악의 실행 중에 어떤 값으로 변수가 설정되었는지 확인합니다.

예를 들어, 각 최고 주행에 대해 비행기의 날개가 특정 크기인 것을 탐지하는 경우, 특정 날개 크기가 비행기의 장거리 비행에 최적일 수 있다고 결론 내릴 수 있다.

반대로, 각각의 최악의 달리기의 경우, 비행기의 날개가 특정 각을 이루고 있다면, 우리는 그 특별한 각이 우리 비행기의 날개에 나쁜 선택이 될 것이라고 결론을 내릴 것입니다.

일반적으로 우리는 최적의 평면을 생성해야하는 각 값에 대한 확률 분포를 생성 할 것이며, 가능성은 더 이상 무작위가 아니라 우리가 받은 피드백을 기반으로합니다.

따라서이 방법은 일반적인 강화 학습 프로세스에서 문제 (각 변수의 값)에 대한 최적의 솔루션을 결정하기 위해 런으로부터의 피드백 (비행기가 얼마나 멀리 비행했는지)을 사용합니다.

--

#h2 신경망 네트워크(neural network)

몇 가지 유명한 고전 기계 학습 알고리즘으로 독자들을 새롭게 만든 후에, 우리는 이제 신경 네트워크를 소개하고 그것들이 어떻게 작동하는지 그리고 우리가 간단하게 요약한 알고리즘과 어떻게 다른지 더 자세히 설명할 것이다.

신경망은 알고리즘을 학습하는 또 다른 기계로 인기가 높고 사용 빈도가 적은시기를 알고 있습니다.

 우리가 다음 장과 그 다음 장에 바칠 신경망을 이해하는 것은 이 책의 내용을 따르기 위한 핵심이다.

신경 회로망의 첫 번째 예는 1957 년 Frank Rosenblatt가 발명 한 퍼셉트론 (perceptron)이라고 불렀습니다. 퍼셉트론은 입력 및 출력 레이어로만 구성된 네트워크입니다.

바이너리 분류의 경우 출력 레이어에는 하나의 뉴런이나 단위 만 있습니다. 퍼셉트론은 처음부터 매우 유망한 것으로 보였지만 직선적으로 분리 가능한 패턴만을 배울 수 있다는 것을 빨리 깨달았습니다.

예를 들어, Marvin Minsky와 Seymour Papert는 XOR 논리 함수를 배울 수 없다는 것을 보여주었습니다. 가장 기본적인 표현에서, 퍼셉트론은 단순히 하나의 뉴런과 입력, 즉 여러 뉴런으로 구성 될 수있는 입력의 표현입니다.

뉴런에 다른 입력이 주어지면 수식으로 활성화 값을 정의합니다. \\(a(x) = \sum_{i} w_i x_i\\) 여기서 x_i는 입력 뉴런의 값이고, w_i는 뉴런 i와 출력 간의 연결 값입니다.

우리는 다음 장에서 훨씬 더 자세하게 이것을 배울 것입니다. 왜냐하면 이제는 퍼셉트론이 로지스틱 회귀 알고리즘과 많은 유사점을 공유한다는 것을 알아야합니다.

그리고 퍼셉트론은 선형 분류자에 의해 제한된다. 뉴런 내부 상태로 간주되어야 할 활성화 값이 고정 임계값 b보다 크면 뉴런은 활성화될 것입니다. 즉, 작동하거나 그렇지 않으면 작동하지 않습니다.


![퍼셉트론]./deep_picture/perseptron.PNG]

세 개의 입력 장치 (뉴런)와 하나의 출력 장치 (뉴런)가있는 간단한 퍼셉트론

따라서 <w, x> = 0 인 모든 벡터 x는 R3에서 하이퍼 평면을 정의합니다 (3은 x의 차원이지만 일반적으로는 임의의 정수가 될 수 있습니다).

따라서, <w, x>> 0를 만족하는 임의의 벡터 x는 w에 의해 정의 된 하이퍼 - 평면의 측면상의 벡터이다. 이것은 퍼셉트론이 어떻게 하이퍼평면을 정의하고 그것을 분류 자로 사용 하는지를 명확하게합니다.

일반적으로 0 대신에 임의의 실수 b로 임계 값을 설정할 수 있습니다.이 값은 하이퍼 평면을 원점에서 멀리 이동시키는 효과가 있습니다.

그러나이 값을 추적하기보다는 일반적으로 네트워크에 바이어스 단위를 포함합니다.이 단위는 연결된 가중치 -b가있는 항상 (값 = 1) 특수 뉴런입니다.


이 경우 연결 가중치가 -b 값을 가지면 활성화 값은 a(x) = \\(sum_i w_i x_i\\) 가되고 a (x)> 0으로 설정하는 것은  \\(sum_i w_i x_i\\) > b.로 설정하는 것과 같다.

![가중ㅊ](./deep_picture/inputlayer.PNG)
출력 벡터에 바이어스 단위가 추가 된 퍼셉트론 바이어스 단위는 항상 켜져 있습니다.

퍼셉트론은 퍼포먼스가 제한적이지만 신경망의 첫 번째 사례이기 때문에 역사적으로 매우 중요합니다.

신경망은 물론 하나의 출력 뉴런을 가질 필요가 없으며 실제로 일반적으로 출력뉴런은 없습니다.

네트워크에 하나 이상의 출력 뉴런이있는 경우 각 출력 뉴런에 대해 동일한 프로세스를 반복 할 수 있습니다.

각각의 가중치는 두 개의 지수, i와 j로 표시됩니다.가중치가 입력 레이어의 뉴론 i를 출력 레이어의 뉴론 j에 연결하고 있음을 나타냅니다.
출력 레이어의 각 뉴런에 값 1로 연결된 바이어스 장치와의 연결도 있습니다.
활성화 값에 대해 다른 활동 함수를 정의 할 수 있다는 점도 유의해야합니다.

우리는 활성화 값을 a (x) = \\(sum_i w_i x_i -b\\)로 정의했다. (이제부터는 바이어스가이 공식에 포함된다고 가정 할 것이다) 활성화가 0보다 큰 경우 뉴런이 활성화된다고 말했다.

앞으로 살펴 보 겠지만, 이것은 이미 활성화 함수 즉, 뉴런의 내부 상태에 대해 정의 된 함수를 정의합니다. 활성화를 0보다 크게하면 뉴런이 활성화되기 때문에 이것을 임계점 활동이라고합니다

그러나 신경망에는 활성화 값으로 정의 할 수있는 다양한 활동 함수가있을 수 있으며 다음 장에서 자세히 다룰 것입니다.

#h2 딥러닝(deep learning)

이전 단락에서는 신경 네트워크의 매우 간단한 예인 피드 - 포워드 1 계층 네트워크를 소개했다.

정보가 입력에서 출력으로 진행되고 결코 루프백되지 않으므로 피드 포워드라고하며 입력 레이어 외에도 1 개의 출력 레이어 만 있기 때문에 1 개의 레이어.

이것은 일반적인 경우는 아니다. 우리는 이미 `1 층 피드 포워드 네트워크의 한계를 선형 적으로 분리 가능한 데이터에만 적용 할 수 있다고 언급했으며 특히 논리적 XOR 기능을 근사시킬 수 없다`고 언급했습니다.

그러나 입력 및 출력 레이어 사이에 추가 레이어가있는 네트워크가 있습니다. 이러한 레이어를 숨겨진 레이어라고합니다.

숨겨진 레이어가있는 피드 전달 네트워크는 입력에서 숨겨진 레이어를 통해 입력을 가져 와서 출력을 정의하는 함수를 정의하는 출력 레이어로 정보를 이동합니다.

유니버설 정리 (Universal Theorem)라는 정리가 있습니다.이 정리는 적어도 하나의 숨겨진 레이어가있는 신경망으로 모든 함수를 근사 할 수 있다고 말하면서 왜 다음 장에서 이것이 사실인지에 대한 직감을 줄 것입니다.

오랜 시간 동안,이 정리(universal)와 복잡한 네트워크 작업의 어려움을 감안할 때, 사람들은 단 하나의 숨겨진 계층으로 얕은 네트워크로 작업 해 왔습니다.

그러나 최근에 사람들은 많은 숨겨진 레이어가있는 더 복잡한 네트워크가 얕은 레이어에서 볼 수없는 추상 수준을 이해할 수 있음을 깨닫게되었습니다.게다가, 뉴런들이 그들 자신에게 정보를 다시 제공할 수 있는 반복적인 네트워크가 도입되었다.

또한 일부 신경 네트워크의 구조는 기억을 만들 수 있는 에너지 기능을 정의하도록 허용할 수 있다.
이 모든 흥미로운 기능은 다음 장에서 논의 될 것이며, 우리는 심화 학습에서 가장 최근 개발을 탐구 할 것입니다.

![신경망 네트워크와 하나의 히든레이어.][./deep_picture/hiddenlayer.PNG]


--

#h2 현실의 실행(Applications in real life)
일반적으로 기계 학습, 특히 심층 학습은 예측품질, 기능 탐지 및 분류의 품질면에서 점점 더 놀라운 결과를 산출합니다.최근의 결과 중 많은 부분이 최근 몇 년 사이에 보도되었습니다. 많은 전문가들이 곧 기계가 인간보다 더 지능적 일 것이라고 걱정하고 있다는 점은 진도의 걸음입니다.

2015년 10월 14일 유엔 회의에서 인공지능 전문가와 많은 분야의 연구원들은 초지능급 기계가 인류에게 부과할 수 있는 위험을 방지하기 위한 윤리 지침을 정의할 필요성에 대해 경고했다.

그러한 두려움은 컴퓨터가 인간에게 기계보다 우월함을주는 직감으로 생각되는 게임에서 최고의 인간 챔피언을 이길 수 있었던 최근의 놀라운 결과에서 비롯됩니다.

AlphaGo는 2016 년 세계 챔피언 Lee Sedol을 제치고 뉴스를 만들었던 깊은 학습을 기반으로 한 인공 지능 기계입니다.

  2016 년 1 월 AlphaGo는 유럽 챔피언 Fan Hui를 이길 때 이미 뉴스를 만들었지 만, 당시 세계 챔피언을이기는 것은 어려울 듯했습니다.

 AlphaGo는 빠른 시일 내에 두 달 간의 상대를 4-1로 물리 치고이 놀라운 업적을 달성 할 수있었습니다.

축하의 이유는 Go에 체스와 같은 다른 게임보다 가능한 많은 게임 변형이 있기 때문이며 가능한 모든 동작을 미리 고려할 수는 없습니다.

또한 Go에서는 체스와 달리 보드의 돌 하나의 현재 위치 나 가치를 판단하기가 매우 어렵습니다.

AlphaGo의 강점은 재생하도록 프로그래밍되지 않았지만 강화 학습과 심층 학습 기술을 사용하여 수천 게임을 플레이하여 게임을 배웠다는 것입니다.

학습 능력은 기계 학습을 렌더링하는 것, 특히 깊은 학습, 특히 문제 해결에 대한 완전히 다른 접근 방식입니다. 깊은 학습은 인간이 거의 또는 전혀 도움을받지 않고 스스로 학습 할 수있는 프로그램을 만드는 것에 관한 것입니다.

그러나 깊이있는 학습이 상당한 성공을 거둔 다양한 분야는 게임에만 국한되지 않습니다.

Kaggle (http://www.kaggle.com)은 다양한 기계 학습 대회를 주최하는 웹 사이트입니다. 이들은 사용되는 분야와 용도에 따라 광범위하게 변화합니다.

2013 년 오레곤 대학 (University of Oregon)은 실제 세계 오디오 데이터의 표준 녹음을 사용하여 새를 탐지하고 식별하는 기계 학습 기술을 사용하도록 요청받은 경쟁사를 후원했습니다.

조류 개체 추세에 대한 이해를 높이기 위해서는 값 비싼 인력이 필요합니다. 기계 학습은 단순히 오디오 녹음을 듣는 것으로 어떤 새들이 있는지를 자동으로 식별하여이 문제를 해결하는 데 도움이됩니다

아마존은 최근 직원들이 내부 컴퓨터와 네트워크에 액세스 할 수 있도록 허용하는 문제에 대한 또 다른 경쟁을 시작하여 성공적인 솔루션으로 인하여 감독 감독에 소요되는 비용이 많이 소요될 것으로 예상했습니다.

시카고 보건부 (Health Department of Health)는 2015 년에 "주어진 기상 위치 테스트 및 데이터 분사 ... 언제 다른 종류의 모기가 웨스트 나일 바이러스에 양성 반응을 보일지"에 대한 경쟁을 개최했습니다.

  2015 년 8 월에 경쟁 업체가 서호주 전역의 임대 가격을 예측하고 2016 년 2 월 프랑스 은행 인 BNP 파리 바 (BNP Paribas)는 청구 관리 프로세스를 가속화하기위한 경쟁을 시작했습니다.

이는 기계 학습을 통해 해결할 수 있는 다양한 문제에 대한 몇 가지 아이디어를 제공하며, 이러한 모든 경연대회가 최고의 솔루션을 위해 상을 제공한다는 점에 유의해야 합니다.

넷플릭스는 2009년 100만 달러(약 1억 원) 규모의 영화 예측 시스템 정확도를 높이기 위한 경쟁을 시작했고, 데이터 과학자의 일자리는 일상적으로 가장 높은 출연료와 가장 많은 출연료로 꼽힌다.

기계학습은 자율주행차, 군용 드론, 표적정찰시스템 등 의료 분야에 걸쳐 일상적으로 사용되며, 의사노트를 읽어 잠재적인 건강 문제를 찾아낼 수 있는 애플리케이션, 얼굴 인식 감시 시스템 등이 있다.

광학 문자 인식은 예를 들어 우체국에서 봉투의 주소를 읽는 데 널리 사용되며 MNIST 데이터 세트를 사용하여 숫자 인식에 신경망을 적용하는 방법을 보여줍니다.

감독되지 않은 심층 학습은 NLP (Natural Language Processing)에서 많은 응용 프로그램과 훌륭한 결과를 발견했으며, 거의 각자가 NLP에 깊은 학습의 NLP 응용 프로그램을 사용합니다. 그들의 가상 조수 (예 : 시리).

기계 학습은 또한 지문, DNA 또는 망막 인식과 같은 사람의 신체적 특징을 인식하는 등의 생체 인식 응용 프로그램을 찾습니다.

또한 최근 몇 년간 자동차 자율 주행이 개선되어 현재 현실화되고 있습니다. 기계 학습은 사진 앨범의 카탈로그 사진, 또는 더 중요한 것은 인공위성 이미지에 적용하여 도시 환경인지 여부에 따라 다른 이미지를 설명 할 수 있으며 숲, 얼음 지역, 수면 확장, 등등.

요약하면, 기계 학습은 최근 우리 생활의 거의 모든 측면에서 응용 프로그램을 발견했으며 정확성과 성능은 점점 더 빠르고 더 우수한 컴퓨터 덕분에 지속적으로 개선되었습니다.

--

#H2 유명한 오픈소스 패키지.

기계 학습은 대중적이고 경쟁적인 분야이며 고전적인 기계 학습 알고리즘의 대부분을 구현하는 많은 오픈 소스 패키지가 있습니다.

scikit-learn은 지원 벡터 머신(SVM), 가장 가까운 이웃, 랜덤 포리스트, 선형 회귀, k-평균, 의사결정 신경 알고리즘과 같은 대부분의 고전적 머신 학습 분류기, 레저 및 클러스터링 알고리즘을 구현하는 라이브러리를 제공합니다.

기본 클래스 sklearn에는 sklearn.ensemble, sklearn.linear_model, sklearn과 같이 선택한 알고리즘의 유형에 따라 사용 가능한 여러 패키지가 있습니다. naive_bayes, sklearn.neural_network, sklearn.svm 및 sklearn.tree.

교차 검증을 수행하고 최상의 기능을 선택하는 데 도움을주는 도우미도 있습니다. 모든 기능을 추상적으로 설명하는 데 시간을 소비하는 대신 멀티 레이어 신경망을 사용하는 간단한 예제부터 시작하겠습니다.'

scikitlearn 라이브러리는 각 기계 학습 알고리즘에 대해 유사한 서명이있는 메소드를 사용하므로 분류 기준은 동일한 공통 기능을 공유합니다.

또한 독자는 처음부터 신경망을 만드는 데 시간을 낭비 할 필요없이 신경망이 할 수있는 것의 맛을 빨리 시작할 수 있기를 바랍니다.

다음 장에서는 다른 유형의 심층 학습 신경망에 대한 다른 라이브러리 및보다 복잡한 구현에 대해 설명하지만, 현재 사용자는 해당 기능에 대한 빠른 아이디어를 얻을 수 있습니다.

예를 들어 scikit-learn으로 다층 신경망을 사용하려면 다음과 같이 입력하여 프로그램에서 가져올 수 있습니다.
`from sklearn.neural_network.multilayer_perceptron import MLPClassifie`

# RNN 부분

RNN은 반복적으로 동일한 함수를 시퀀스에 적용하기 때문에 생긴 이름이다. RNN은이 함수로 정의 된 반복 관계로 작성할 수 있습니다.

$S_t= f(S_{t-1}, X_t)$

여기에서 $S_t$ - 단계 t에서의 상태는 이전 단계의 상태, 즉 t-1에서 함수 f와 현재 단계에서 입력 $X_t$에 의해 계산됩니다. 이 반복 관계는 다음 그림 에서처럼 상태가 이전 상태에 대한 피드백 루프를 통해 시퀀스를 단계적으로 전개하는 방식을 정의합니다

![피규어 폼][./deep_picture/figureform.PNG]

left : RNN 반복 관계의 시각적 그림: $S_t=s_{t-1}*W+X_t*U$ 최중 출력은 $O_t = V*S_t$

right: RNN 상태가 순서 t-1,t,t+1 반복적으로 전개된다.

매개변수 U,V,W은 모든 단계 사이에서 공유된다

여기서 f는 임의의 차등 함수 일 수 있다. 예를 들어, 기본 RNN은 다음과 같은 반복 관계로 정의.

$S_t = tanh(S_{t-1} * W + X_t * U)$

여기서 W는 상태에서 상태로 선형 변환을 정의하고, U는 입력에서 상태로의 선형 변환
tanh 기능은 logit, tanh 또는 ReLU와 같은 다른 변환으로 대체 될 수 있습니다. 
다음 그림은이 관계를 보여줍니다. 여기서 $O_t$는 네트워크에서 생성 된 출력입니다.

예를 들어, 단어 수준 언어 모델링에서 입력 X는 입력 벡터 (X1 ... Xt ...)로 인코딩 된 일련의 단어가됩니다.

상태 S는 일련의 상태 벡터 (S1 ... St ...)가됩니다. 출력 O는 시퀀스의 다음 단어의 확률 벡터 (O1 ... Ot ...)의 시퀀스가됩니다.

RNN에서 각 상태는 이 반복 관계를 통해 이전의 모든 계산에 의존합니다.

이것의 중요한 의미는 상태 S가 이전 단계에 기초한 정보를 포함하고 있기 때문에 rnn은 시간의 흐름에 따른 메모리를 가지고 있다는 것.

이론적으로 RNN은 임의의 오랜 기간 동안 정보를 기억할 수 있지만 실제로는 몇 단계 만 되돌아 보는 것으로 제한.
-vanising gardient.

RNN은 고정 크기의 입력을 처리하는 데에만 국한되지 않으므로 다양한 길이의 시퀀스 나 다양한 크기의 이미지와 같이 신경망을 사용하여 계산할 수있는 가능성을 실제로 확장합니다.

다음 그림은 우리가 만들 수있는 시퀀스의 조합을 시각적으로 보여줍니다. 다음은 이러한 조합에 대한 간단한 참고 사항입니다.

![이미지 폼][./deep_picture/imageform.PNG]


• 일대일 : 이는 피드 포워드 신경망 및 길쌈 신경 네트워크와 같이 비 순차적 처리입니다.
피드 포워드 네트워크와 RNN을 단일 시간 단계에 적용하는 것은별로 다르지 않습니다.
일대일 처리의 한 예는 장 (Chapter 5, Image Recognition 참조)에서의 이미지 분류입니다.

• 일대 다 : 이미지에서 캡션 생성과 같은 단일 입력을 기반으로 시퀀스를 생성합니다 [4].

• 다 대일 (Many-to-one) : 시퀀스를 기반으로 단일 결과를 출력합니다 (예 : 텍스트의 감정 분류).

• 다 대다 간접 : 시퀀스는 상태 벡터로 인코딩되고, 그 후에이 상태 벡터는 언어 번역 [5], [6]과 같은 새로운 시퀀스로 디코드됩니다.

• 다 대다 직접 : 음성 인식에서 프레임 음소 레이블링과 같은 각 입력 단계에 대한 결과를 출력합니다 (음성 인식 섹션 참조).



## RNN 구현 및 훈련 방법.


순서대로 세기.

입력 및 출력의 예는 다음과 같습니다.
In:  (0, 0, 0, 0, 1, 0, 1, 0, 1, 0) Out:  3

![기본 rnn][./deep_picture/basicrnn.PNG]

네트워크에는 입력 가중치 U와 반복 가중치 W의 두 가지 매개 변수 만 있습니다.
출력 가중치 V는 1로 설정되므로 마지막 상태를 출력 y로만 읽습니다.
이 네트워크에 의해 정의 된 반복 관계는 $S_t = S_{t-1} * W + X_t * U$이다.
이 공식에서 비선형 함수를 적용하지 않기 때문에 선형 모델이라는 점에 유의하십시오.

코드로하면 다음과 같다.
def step(s, x, U, W):
    return x * U + s * W

3은 우리가 출력하기를 원하는 숫자이고 세 개가 있기 때문에 좋은 해결책은 그냥 시퀀스 전체의 입력 합을 얻는 것입니다.
U = 1로 설정하면 입력이 수신 될 때마다 전체 값을 얻습니다. W = 1로 설정하면 누적 될 값은 결코 감소하지 않습니다. 따라서이 예제에서는 원하는 출력을 얻습니다. 3

## 시간에 따른 역전파

시간에 따른 역전파 알고리즘을 통한 역전파는 우리가 반복되는 네트워크를 훈련하는 데 사용하는 일반적인 알고리즘이다.
-이미 좆같은 2장에서 논의함

정규 역전파랑 시간에 따른 역전파는 그리 큰 차이 나지않음.
주요 차이점은 회귀 네트워크 시간 단계의 특정 번호에 대한 시간을 통해 전개 될 필요가 있다는 것이다.

이 전개는 앞의 그림 (입력에서 1을 세는 기본 RNN)에 설명.전개가 완료되면 multi feedforward 네트워크와 매우 유사한 모델이 완성.

유일한 차이점은 각 레이어가 다중 입력 (이전 상태, $S_{t-1}$)을 가지며 현재 입력 ($X_t$)과 매개 변수 (여기에서 U 및 W)가 각 레이어간에 공유된다는 것입니다
순방향 전달은 시퀀스를 따라 RNN의 래핑을 해제하고 각 단계에 대한 일련의 활동을 구축합니다. 일련의 입력 시퀀스 X가있는 진행 단계는 다음과 같이 구현할 수 있습니다.

~~~python
def forward(X, U, W):
    # Initialize the state activation for each sample along the sequence
    S = np.zeros((number_of_samples, sequence_length+1))
    # Update the states over the sequence
    for t in range(0, sequence_length):
        S[:,t+1] = step(S[:,t], X[:,t], U, W)  # step function
    return S
~~~
이 전진 단계 후에, 배치의 각 단계 및 각 샘플에 대해 S로 표시되는 결과 활성화가 나타납니다.
우리는 더 많거나 적은 연속적인 출력 (모든 것을 합한 것)을 출력하기를 원하기 때문에 평균 제곱 오차 비용 함수를 사용하여 목표 및 출력 y에 대한 출력 비용을 정의합니다.

cost = np.sum((targets – y)**2) 

앞으로 단계와 비용 함수가 생겨서 그래디언트가 어떻게 뒤쪽으로 전달되는지 정의 할 수 있습니다.

먼저, 비용 함수와 관련하여 출력 y의 기울기를 구해야한다.(∂ξ/∂y).

이 그래디언트가 있으면 앞으로 단계에서 작성한 액티비티 스택을 통해 이를 뒤로 전파 할 수 있습니다.
이 역방향 패스는 각 시간 단계에서 오류 파생물을 누적하기 위해 스택에서 활동을 팝합니다. 이 그라디언트를 네트워크를 통해 전파하는 반복 관계는 다음과 같이 작성할 수 있습니다.



수학식은 차라리 구글 디벨로퍼참조.

https://google-developers.appspot.com/machine-learning/crash-course/backprop-scroll/?hl=ko&refresh=1





~~~python
def backward(X, S, targets, W):
    # Compute gradient of output
    y = S[:,-1]  # Output `y` is last activation of sequence
    # Gradient w.r.t. cost function at final state
    gS = 2.0 * (y - targets)    # Accumulate gradients backwards
    gU, gW = 0, 0  # Set the gradient accumulations to 0
    for k in range(sequence_len, 0, -1):        # Compute the parameter gradients and accumulate the          results.
        gU += np.sum(gS * X[:,k-1])
        gW += np.sum(gS * S[:,k-1])        # Compute the gradient at the output of the previous layer
        gS = gS * W
    return gU, gW
~~~

그라디언트 디센트를 사용하여 네트워크를 최적화하려고 할 수 있습니다.

~~~python
learning_rate = 0.0005 # Set initial parameters
parameters = (-2, 0)  # (U, W) 
# Perform iterative gradient descent
for i in range(number_iterations):
# Perform forward and backward pass to get the gradients
    S = forward(X, parameters(0), parameters(1))
    gradients = backward(X, S, targets, parameters(1))
    # Update each parameter `p` by p = p - (gradient *      learning_rate).
    # `gp` is the gradient of parameter `p`
    parameters = ((p - gp * learning_rate) for p, gp in zip(parameters, gradients))
~~~



![그래디언트 폭발][./deep_picture/gradient_explosion.PNG]

하지만 문제가 있습니다. 이 코드를 실행하려고하면 최종 매개 변수 U 및 W가 숫자가 아닌 숫자 (NaN)로 끝나는 경향이 있습니다.

  다음 그림과 같이 오류 표면에 매개 변수 업데이트를 플로팅하여 어떤 일이 발생했는지 조사해 봅시다.

파라미터가 오버 슈트되고 대략 히트 (U = W = 1.5) 될 때까지 파라미터가 최적 (U = W = 1) 방향으로 천천히 이동합니다.

  이 시점에서 그래디언트 값이 폭발하고 매개 변수 값이 플롯 바깥으로 점프합니다.

  이 문제는 폭발 그라데이션으로 알려져 있습니다. 다음 섹션에서는 이것이 왜 발생하는지 자세히 설명하고 어떻게 예방하는지 설명합니다.


## 배니싱, 폭발 그래디언트

RNN은 피드 포워드 또는 컨볼루션 네트워크보다 훈련하기가 더 어려울 수 있습니다. RNN의 반복적 인 특성 때문에 모든 가중치 행렬이 모든 상태 업데이트를 계산하는 데 사용되는 몇 가지 어려움이 발생합니다 [9,10]

앞의 그림의 마지막 섹션의 끝 부분에는 폭발적인 그라디언트가 묘사되어 장기 구성 요소의 폭발로 RNN 교육이 불안정한 상태로 바뀝니다.

폭발적인 그라디언트 문제 외에도 반대 상황이 발생하면 사라지는 그라디언트 문제가 있습니다.
롱텀컴포넌트는 기하 급수적으로 빠르게 0이되고, 모델은 시간적으로 먼 사건을 통해 학습 할 수 없습니다.
이 섹션에서는 문제를 자세히 설명하고 문제를 처리하는 방법에 대해서도 설명합니다.

폭발하는 것과 사라지는 그라디언트는 그라디언트를 역방향으로 전파하는 반복 관계가 기하학적 순서를 형성한다는 사실로부터 발생합니다

폭발하는 것과 사라지는 그라디언트는 모두 재발 관계가 전파된다는 사실에서 비롯된다.
시간의 경과에 따른 그래디언트 (gradient)는 기하학적 시퀀스를 형성한다 :

$\frac{aS_t}{aS_{t-m}} = \frac{\frac{aS_t}{aS_{t-1}}*....*aS_{t-m+1}}{aS_{t-m}}=W^m$

우리는 단순한 선형 RNN에서 만약 [W] >1 이라면 그레디언트가 기하급수로 증가한다.
이것은 폭발 그라데이션으로 알려져 있습니다 (예 : W = 1.5에서 50 시간 간격은 W50 = 1.550 ≈ 6 * 108).

  W | <1 라면 그래디언트가 감소한다. 이것이 배니싱 그래디언트 (예를 들어 W = 0.6 이상의 20 시간 간격은 W20 = 0.620 ≈ 3 * 10-5 임).


가중치 매개변수 파라미터 w가 스칼라 대신 행렬이라면 배니싱 혹은 폭발 그래디언트는 W의 최대 고유치(p)와 관련있다.(스펙트럼반경이러고도함)

그라디언트가 사라지려면 ρ <1이면 충분하며, ρ> 1 인 경우 그라디언트가 폭발

다음 그림은 폭발 그라디언트의 개념을 시각적으로 보여줍니다.

우리가 훈련하는 비용 표면은 매우 불안정합니다.

작은 단계를 사용하여 비용 함수의 안정적인 부분으로 이동할 수 있습니다.이 부분에서는 그래디언트가 낮고 비용이 급격히 증가하고 그에 해당하는 거대한 기울기가 발생합니다.

이 그라디언트가 너무 크기 때문에 매개 변수에 큰 영향을 미칩니다. 그들은 원래 있던 곳과는 거리가 먼 비용면에서 끝날 것입니다. 그래디언트 강하 학습이 불안정하고 심지어 경우에 따라 불가능 해집니다.

![폭발그래디언트](./deep_picture/explo_gradi.PNG)

그라디언트가 커질 수있는 크기를 조절하여 폭발하는 그라디언트 효과에 대응할 수 있습니다.

• 그래디언트 클리핑, 여기서 그라디언트가 얻을 수있는 최대 값을 임계 값으로 설정합니다 [11].
• 2 차 최적화 (Newton 's method) : 비용 함수의 곡률을 모델링합니다. 곡률을 모델링하면 곡률이 낮은 시나리오에서 큰 단계를 취할 수 있고 곡률이 높은 시나리오에서는 작은 단계를 수행 할 수 있습니다. 계산상의 이유로 일반적으로 2 차 구배의 근사치 만 사용됩니다 
• 모멘텀 또는 로컬 그래디언트에 덜 의존하는 RmsProp과 같은 최적화 방법. 

예를 들어, Rprop을 사용하여 수렴 할 수없는 네트워크를 재교육 할 수 있습니다 (위 그림의 폭발 그라디언트 그림 참조).

Rprop은 모멘텀 매개 변수를 업데이트하기 위해 그래디언트 부호 만 사용하는 모멘텀 형 메서드이므로 폭발 그라디언트의 영향을받지 않습니다.

Rprop 최적화를 실행하면 다음 그림에서 해당 교육이 수렴 함을 알 수 있습니다. 트레이닝이 높은 그래디언트 영역 (U = -1.5, W = 2)에서 시작하는 동안 최적의 위치 (U = W = 1)를 찾을 때까지 빠르게 수렴합니다.
![Rprop](./deep_picture/rprop.PNG)


사라지는 그라디언트 문제는 폭발적인 그라디언트 문제의 반대입니다.기울기는 단계 수에 따라 기하 급수적으로 감소합니다.
이것은 이전 상태의 그래디언트들이 극도로 작아지고 이전의 상태를 기억 못하게 되는 것을 말한다.

초기 시간 단계의 작은 그라디언트는보다 최근의 시간 단계의 큰 그라디언트에 의해 무능해진다.
시간에 따른 역전파는 최근의 활동에 너무 민감하다.

## LSTM

이론적으로, 간단한 RNN은 장기 종속성을 학습 할 수 있지만 실제로는 배니싱그래디언트 때문에 단기 의존성만 학습하는 것으로 제한됩니다.LSTM은 특수하게 조작 된 메모리 셀로 인해 장기 의존성을 처리 할 수 있습니다.

LSTM의 핵심 아이디어는 외부 상태가 없다면 셀 상태가 일정하게 유지되도록 정보를 명시 적으로 기록하거나 제거 할 수있는 셀 상태입니다.

시간 t에 대한이 셀 상태는 다음 그림에서 ct로 표시됩니다.
LSTM 셀 상태는 정보를 전달할 수있는 특정 게이트에서만 변경할 수 있습니다.

이 게이트는 시그모이드 함수와 요소 단위의 곱셈으로 구성됩니다.
로지스틱 함수는 0과 1 사이의 값만 출력하기 때문에 곱셈은 게이트를 통과하는 값을 줄일 수 있습니다. 일반적인 LSTM은 잊어 버린 게이트, 입력 게이트 및 출력 게이트의 세 가지 게이트로 구성됩니다. 이들은 모두 다음 그림에서 f, i 및 o로 표시됩니다. 셀 상태, 입력 및 출력은 모두 벡터이므로 LSTM은 각 시간 단계마다 서로 다른 정보 블록의 조합을 보유 할 수 있습니다. 다음은 각 게이트의 작동 방식을 자세히 설명합니다.

![LSTM](./deep_picture/LSTM.PNG)

LSTM의 셀들 계산식은 다음과 같다.
$x_t, c_t, h_t$는 각각 시간 t에서의 입력, 셀 상태 및 LSTM 출력이다.

$f_t =\sigma(W_fh_{t-1}+U_fx_t+b_f)$

$i_t =\sigma(W_ih_{t-1}+U_ix_t+b_i)$

$a_t = tanh(W_ch_{t-1}+U_cx_t+b_c)$

$o_t=\sigma(W_oh_{t-1}+U_ox_t+b_o)$

$c_t=f_t*c_{t-1}+i_t*a_t$

$h_t=o_t*tanh(c_t)$

LSTM의 첫 번째 게이트는 잊어 버린 게이트입니다. 그것은 우리가 셀 상태를 지우고 싶은지 아닌지를 결정하기 때문에 그   렇게 불린다.

forget 게이트는 이전 출력 $h_{t-1}$과 현재 입력 $x_t$에 대한 결정을 기반으로합니다.
이 정보를 결합하여 로지스틱 함수로 압축하여 셀 벡터의 각 블록에 대해 0과 1 사이의 숫자를 출력합니다.셀과 요소 적으로 곱하기 때문에 0 출력은 특정 셀 블록을 완전히 지우고 1 출력은 해당 셀의 모든 정보를 차단합니다. 이것은 LSTM이 셀 상태 벡터에서 관련없는 정보를 제거 할 수 있음을 의미합니다.

$f_t =\partial(W_fh_{t-1}+U_fx_t+b_f)$


다음 게이트는 어떤 새로운 정보가 메모리 셀에 추가 될지를 결정합니다.
이것은 두 부분으로 이루어집니다. 첫 번째 부분은 정보가 추가 될지 여부를 결정합니다.
입력 게이트에서와 마찬가지로 $h_{t-1}과 x_t$를 결정하고 셀 벡터의 각 셀 블록에 사용할 수있는 로지스틱 함수를 통해 0 또는 1을 출력합니다.
출력 0은 해당 셀 블록의 메모리에 정보가 추가되지 않음을 의미합니다. 결과적으로 LSTM은 셀 상태 벡터에 특정 정보를 저장할 수 있습니다.

$i_t =\partial(W_ih_{t-1}+U_ix_t+b_i)$

추가 된 입력은 이전 출력 $(h_{t-1})$과 현재입력 $(x_t)$에서 파생되며 tanh 함수를 통해 변환됩니다

$a_t = tanh(W_ch_{t-1}+U_cx_t+b_c)$

잊기 및 입력 게이트는 추가할 새 정보와 함께 이전 셀 상태를 추가하여 새 셀을 완전히 결정합니다.

$c_t=f_t*c_{t-1}+i_t*a_t$


마지막 게이트는 출력을 결정합니다. 출력 게이트는 입력으로 $h_{t-1} 및 x_t$를 취하고 각 셀 블록의 메모리에 사용할 수있는 로지스틱 함수를 통해 0 또는 1을 출력합니다. 출력 0은 셀 블록이 정보를 출력하지 않음을 의미하고 출력 1은 전체 셀 블록의 메모리가 셀의 출력으로 전송됨을 의미합니다. 따라서 LSTM은 셀 상태 벡터로부터 특정 정보 블록을 출력 할 수 있습니다.

$o_t=\partial(W_oh_{t-1}+U_ox_t+b_o)$   

출력 된 최종 값은 tanh 함수로 전송 된 셀의 메모리입니다.

$h_t=o_t*tanh(c_t)$

이 모든 수식은 파생 가능하기 때문에 우리는 간단한 RNN 상태를 연결하고 시간에 따른 역 전파를 통해 네트워크를 훈련하는 것처럼 LSTM 셀을 함께 연결할 수 있습니다. 이제 LSTM은 어떻게 사라지는 그라디언트로부터 우리를 보호합니까?

forget 게이트가 1이고 입력 게이트가 0이면 셀 상태는 단계별로 똑같이 복사됩니다. forget게이트 만이 셀의 메모리를 완전히 지울 수 있습니다.

결과적으로 메모리는 오랜 기간 동안 변경되지 않은 상태로 유지 될 수 있습니다.또한 입력이 현재 셀의 메모리에 추가된 tanh 활성화 함수라는 거슬 알수있다

이것은 세포 기억이 폭발하지 않고 매우 안정하다는 것을 의미합니다. LSTM이 실제 어떻게 전개되는지는 다음 그림에 설명되어 있습니다

![LSTM_gate](./deep_picture/LSTM_gate.PNG)

처음에는 4.2 값이 네트워크에 입력으로 제공됩니다. 입력 게이트는 1로 설정되어 완전한 값이 저장됩니다. 그런 다음 다음 두 단계 동안 잊어 버린 게이트는 1로 설정됩니다. 따라서이 단계에서 전체 정보가 유지되고 입력 게이트가 0으로 설정되므로 새로운 정보가 추가되지 않습니다. 마지막으로 출력 게이트가 1로 설정됩니다 , 4.2가 출력되고 변경되지 않음